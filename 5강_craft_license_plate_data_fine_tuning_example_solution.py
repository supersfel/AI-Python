# -*- coding: utf-8 -*-
"""5강_CRAFT_license_plate_data_fine_tuning_example_solution.ipynb의 사본

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tE5Tba0CfAReqNHLoGeAvlQIZdeBgz9H
"""
import cv2

data_dir = '.'

import os
import math
import imgaug
import numpy as np
import matplotlib.pyplot as plt
import sklearn.model_selection
import tensorflow as tf

import keras_ocr

# dataset = keras_ocr.datasets.get_icdar_2013_detector_dataset(
#     cache_dir='.',
#     skip_illegible=False
# )
#
# # print(dataset)
#
# train, validation = sklearn.model_selection.train_test_split(
#     dataset, train_size=0.8, random_state=42
# )
# augmenter = imgaug.augmenters.Sequential([
#     imgaug.augmenters.Affine(
#     scale=(1.0, 1.2),
#     rotate=(-5, 5)
#     ),
#     imgaug.augmenters.GaussianBlur(sigma=(0, 0.5)),
#     imgaug.augmenters.Multiply((0.8, 1.2), per_channel=0.2)
# ])
# generator_kwargs = {'width': 640, 'height': 640}
# training_image_generator = keras_ocr.datasets.get_detector_image_generator(
#     labels=train,
#     augmenter=augmenter,
#     **generator_kwargs
# )
# validation_image_generator = keras_ocr.datasets.get_detector_image_generator(
#     labels=validation,
#     **generator_kwargs
# )
#
# image, lines, confidence = next(training_image_generator)
# canvas = keras_ocr.tools.drawBoxes(image=image, boxes=lines, boxes_format='lines')
# plt.imshow(canvas)
# plt.show()
# detector = keras_ocr.detection.Detector()
#
# batch_size = 1
# training_generator, validation_generator = [
#     detector.get_batch_generator(
#         image_generator=image_generator, batch_size=batch_size
#     ) for image_generator in
#     [training_image_generator, validation_image_generator]
# ]
# detector.model.fit_generator(
#     generator=training_generator,
#     steps_per_epoch=math.ceil(len(train) / batch_size),
#     epochs=1000,
#     workers=0,
#     callbacks=[
#         tf.keras.callbacks.EarlyStopping(restore_best_weights=True, patience=5),
#         tf.keras.callbacks.CSVLogger(os.path.join(data_dir, 'detector_icdar2013.csv')),
#         tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(data_dir, 'detector_icdar2013.h5'))
#     ],
#     validation_data=validation_generator,
#     validation_steps=math.ceil(len(validation) / batch_size)
# )
# #
#
# """# 실습 - License Plate Detection Data에 맞게 Fine-Tuning하기
#
# 1.   get_licenseplate_detector_dataset 라는 licnese plate detection data에 대한 정보를 return하는 함수를 새로 작성 (Reference : https://github.com/faustomorales/keras-ocr/blob/master/keras_ocr/datasets.py#L178 )
# 2.   license plate detector 데이터셋에 맞게 CRAFT 파라미터 Fine-Tuning
#
# # 정보 Return 형태 분석
# """
#
# dataset
#
# type(dataset)
#
# dataset[0]
#
# type(dataset[0])
#
# dataset[0][1]
#
# type(dataset[0][1])
#
# dataset[0][1][0]
#
# type(dataset[0][1][0])
#
# dataset[0][1][0][0]
#
# type(dataset[0][1][0][0])
#
# dataset[0][1][0][0][0]
#
# type(dataset[0][1][0][0][0])
#
# dataset[0][1][0][0][0].shape
#
# def get_licenseplate_detector_dataset():
#
#
#
#
#   return dataset
#
# """# 실습 Solution - License Plate Detection Data에 맞게 Fine-Tuning
#
# ## Licnese Plate Detection Dataset 구글 드라이브 링크 : https://drive.google.com/file/d/1gvD8rsMNFGtu1VxKTwz3_2tQrhE8d9SV/view?usp=sharing
# """
#
import glob

data_dir = '.'


"""## license plate data를 읽어오는 함수 정의"""

def get_licenseplate_detector_dataset(cache_dir=None):
  """
  Args:
      cache_dir: The directory in which to store the data.
  Returns:
      Lists of (image_path, lines, confidence) tuples. Confidence
      is always 1 for this dataset. We record confidence to allow
      for future support for weakly supervised cases.
  """
  if cache_dir == None:
    raise ValueError('cache_dir is None')

  main_dir = os.path.join(cache_dir, 'license_plate_detection_data')
  training_images_dir = os.path.join(main_dir, 'images')
  training_gt_dir = os.path.join(main_dir, 'annotations')

  dataset = []
  for gt_filepath in glob.glob(os.path.join(training_gt_dir, '*.txt')):
    image_id = os.path.split(gt_filepath)[1].split('.')[0]
    image_path = os.path.join(training_images_dir, image_id + '.jpg')
    lines = []
    with open(gt_filepath, 'r') as f:
      for row in f.read().split('\n'):
        current_line = []
        row = row.split(' ')
        character = row[-1][1:-1]

        x1, y1, x2, y1, x2, y2, x1, y2 = map(int, row[:8])
        current_line.append((np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]]), character))
        lines.append(current_line)

    # Some lines only have illegible characters and if skip_illegible is True,
    # then these lines will be blank.
    lines = [line for line in lines if line]
    dataset.append((image_path, lines, 1))

  return dataset

dataset = get_licenseplate_detector_dataset(cache_dir='.')

# train and validation data split
train, validation = sklearn.model_selection.train_test_split(
  dataset, train_size=0.8, random_state=42
)

# set augmenter
augmenter = imgaug.augmenters.Sequential([
  imgaug.augmenters.Affine(
    scale=(1.0, 1.2),
    rotate=(-5, 5)
  ),
  imgaug.augmenters.GaussianBlur(sigma=(0, 0.5)),
  imgaug.augmenters.Multiply((0.8, 1.2), per_channel=0.2)
])

# set training and validation generator
generator_kwargs = {'width': 640, 'height': 640}
training_image_generator = keras_ocr.datasets.get_detector_image_generator(
  labels=train,
  augmenter=augmenter,
  **generator_kwargs
)
validation_image_generator = keras_ocr.datasets.get_detector_image_generator(
  labels=validation,
  **generator_kwargs
)

# draw one sample training image for sanity check
image, lines, confidence = next(training_image_generator)
canvas = keras_ocr.tools.drawBoxes(image=image, boxes=lines, boxes_format='lines')
plt.imshow(canvas)
plt.show()

# set detector and start training
detector = keras_ocr.detection.Detector()
# restore model weights #학습 저장
loading_model_path = os.path.join(data_dir, 'detector_carplate.h5')
if os.path.isfile(loading_model_path) == True:
  detector.model.load_weights(loading_model_path)
  print(loading_model_path + ' model loaded!')

"""## License Plate Detection 데이터에 맞게 Fine-Tuning"""

batch_size = 1
training_generator, validation_generator = [
  detector.get_batch_generator(
    image_generator=image_generator, batch_size=batch_size
  ) for image_generator in
  [training_image_generator, validation_image_generator]
]
detector.model.fit_generator(
  generator=training_generator,
  steps_per_epoch=math.ceil(len(train) / batch_size),
  epochs=1000,
  workers=0,
  callbacks=[
    tf.keras.callbacks.CSVLogger(os.path.join(data_dir, 'detector_carplate.csv'), append=True),
    tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(data_dir, 'detector_carplate.h5'))
  ],
  validation_data=validation_generator,
  validation_steps=math.ceil(len(validation) / batch_size)
)

"""# 학습이 끝난 모델 h5 파일 및 트레이닝 로그 다운로드


"""

# from google.colab import files
# files.download("/content/detector_carplate.h5")
#
# files.download("/content/detector_carplate.csv")

"""# Pre-Trained 모델(1000epoch동안 학습시킨 detector_carplate.h5 파일 구글드라이브 링크) : https://drive.google.com/file/d/1hKD1heE0ju3aiXMwcH6ZKEQHSRcOGJ68/view?usp=sharing

"""

# draw one sample training image for sanity check
image, lines, confidence = next(validation_image_generator)
canvas = keras_ocr.tools.drawBoxes(image=image, boxes=lines, boxes_format='lines')
plt.imshow(canvas)
plt.show()


print(validation)

import imageio

output_folder = 'craft_license_plate_validation_result'

for image_path, _, _ in validation:
  image = keras_ocr.tools.read(image_path)

  output_image_path = os.path.join(output_folder, image_path.split('/')[-1])

  # detector prediction
  pred_boxes = detector.detect(np.expand_dims(image, axis=0))

  for each_pred in pred_boxes[0]:
    left, top = each_pred[0]
    right, bottom = each_pred[2]
    canvas = cv2.rectangle(image, (left, top), (right, bottom), (0,255,0), 3)

  imageio.imwrite(output_image_path, canvas)
  print(output_image_path + ' saved!' )

"""## 예측결과 압축후 다운로드"""

# !zip -r /content/craft_license_plate_validation_result.zip /content/craft_license_plate_validation_result

# from google.colab import files
# files.download("/content/craft_license_plate_validation_result.zip")
#

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_선형회귀",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSdTJ9ZwcaJzHjWIGBbCJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supersfel/AI-Python/blob/main/01_%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU5w6aM8FNVO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "#오류해결\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# 선형회귀 모델(Wx + b)을 위한 tf.Variable을 선언합니다.\n",
        "W = tf.Variable(tf.random.normal(shape=[1]))\n",
        "b = tf.Variable(tf.random.normal(shape=[1]))\n",
        "\n",
        "@tf.function\n",
        "def linear_model(x):\n",
        "  return W*x + b\n",
        "\n",
        "# 손실 함수를 정의합니다.\n",
        "# MSE 손실함수 \\mean{(y' - y)^2}\n",
        "@tf.function\n",
        "def mse_loss(y_pred, y):\n",
        "  return tf.reduce_mean(tf.square(y_pred - y))\n",
        "\n",
        "# 최적화를 위한 그라디언트 디센트 옵티마이저를 정의합니다.\n",
        "optimizer = tf.optimizers.SGD(0.01)\n",
        "\n",
        "# 최적화를 위한 function을 정의합니다.\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = linear_model(x)\n",
        "    loss = mse_loss(y_pred, y)\n",
        "  gradients = tape.gradient(loss, [W, b])\n",
        "  optimizer.apply_gradients(zip(gradients, [W, b]))\n",
        "\n",
        "# 트레이닝을 위한 입력값과 출력값을 준비합니다.\n",
        "x_train = [1, 2, 3, 4]\n",
        "y_train = [2, 4, 6, 8]\n",
        "\n",
        "# 경사하강법을 1000번 수행합니다.\n",
        "for i in range(10000):\n",
        "  train_step(x_train, y_train)\n",
        "\n",
        "# 테스트를 위한 입력값을 준비합니다.\n",
        "x_test = [3.5, 5, 5.5, 6]\n",
        "# 테스트 데이터를 이용해 학습된 선형회귀 모델이 데이터의 경향성(y=2x)을 잘 학습했는지 측정합니다.\n",
        "# 예상되는 참값 : [7, 10, 11, 12]\n",
        "print(linear_model(x_test).numpy())"
      ]
    }
  ]
}